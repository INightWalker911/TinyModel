{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub tensorflow opencv-python matplotlib"
      ],
      "metadata": {
        "id": "xx68sMk8xeDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π, –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
      ],
      "metadata": {
        "id": "ppldRrhnDuEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import os\n",
        "\n",
        "if os.path.exists(\"my_dataset_final\"):\n",
        "    shutil.rmtree(\"my_dataset_final\")\n",
        "\n",
        "\n",
        "import kagglehub\n",
        "print(\"–°–∫–∞—á–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç\")\n",
        "path = kagglehub.dataset_download(\"akhatova/pcb-defects\")\n",
        "print(f\"–ü—É—Ç—å –∫ —Ñ–∞–π–ª–∞–º: {path}\")\n",
        "\n",
        "\n",
        "source_images = os.path.join(path, \"PCB_DATASET\", \"images\")\n",
        "base_dir = \"my_dataset_final\"\n",
        "target_classes = ['Missing_hole', 'Mouse_bite', 'Open_circuit', 'Short', 'Spur', 'Spurious_copper']\n",
        "\n",
        "print(\"–ö–æ–ø–∏—Ä—É–µ–º –ø–∞–ø–∫–∏\")\n",
        "for cls in target_classes:\n",
        "    src = os.path.join(source_images, cls)\n",
        "    dst = os.path.join(base_dir, cls)\n",
        "\n",
        "    if os.path.exists(src):\n",
        "        shutil.copytree(src, dst)\n",
        "        print(f\"   + {cls}: –ì–æ—Ç–æ–≤–æ\")\n",
        "    else:\n",
        "        print(f\"   - {cls}: –ù–µ –Ω–∞–π–¥–µ–Ω–æ\")\n",
        "\n",
        "\n",
        "print(\"–†–µ–∑—É–ª—å—Ç–∞—Ç\")\n",
        "\n",
        "IMG_SIZE = (96, 96)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    base_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(f\"–ö–ª–∞—Å—Å—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {train_ds.class_names}\")\n"
      ],
      "metadata": {
        "id": "wkRO0UGzyzOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ó–∞–¥–∞–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –¥–∞–Ω–Ω—ã—Ö"
      ],
      "metadata": {
        "id": "oeMWULozD3Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path('my_dataset_final')\n",
        "\n",
        "IMG_SIZE = (96, 96)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=IMG_SIZE,\n",
        "  batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=IMG_SIZE,\n",
        "  batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "isnmYALwzr5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"
      ],
      "metadata": {
        "id": "nz8oCdUsDpgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Rescaling(1./255, input_shape=(96, 96, 3)),\n",
        "\n",
        "  # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è\n",
        "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "\n",
        "  # –°–≤–µ—Ä—Ç–∫–∏\n",
        "  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "  tf.keras.layers.Dense(len(class_names))\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "u0EfK3c_DmPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –û–±—É—á–µ–Ω–∏–µ"
      ],
      "metadata": {
        "id": "nfo8l27UEC5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "print(f\"\\n>>> –°—Ç–∞—Ä—Ç –æ–±—É—á–µ–Ω–∏—è –Ω–∞ {EPOCHS} —ç–ø–æ—Ö...\")\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "id": "iHpgl0XxEB7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ö–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ"
      ],
      "metadata": {
        "id": "PkVOQlh9El04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –§—É–Ω–∫—Ü–∏—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏\n",
        "def representative_data_gen():\n",
        "  for input_value, _ in train_ds.take(100):\n",
        "    yield [tf.cast(input_value, tf.float32)]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# –í–∞–∂–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è ESP32\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "id": "XayIMGT6EI2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª"
      ],
      "metadata": {
        "id": "Ypp6bYFPF6LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hex_to_c_array(hex_data, var_name):\n",
        "    c_str = f'const unsigned char {var_name}[] = {{'\n",
        "    c_str += ', '.join([f'0x{hex_data[i:i+2]}' for i in range(0, len(hex_data), 2)])\n",
        "    c_str += '};\\n'\n",
        "    c_str += f'const unsigned int {var_name}_len = {len(hex_data) // 2};\\n'\n",
        "    return c_str\n",
        "\n",
        "with open('model_data.h', 'w') as f:\n",
        "    f.write(hex_to_c_array(tflite_model.hex(), 'model_data'))\n",
        "\n",
        "print(\"\\nüéâ –ì–û–¢–û–í–û! –§–∞–π–ª model_data.h —Å–æ–∑–¥–∞–Ω. –°–∫–∞—á–∞–π –µ–≥–æ.\")"
      ],
      "metadata": {
        "id": "gsJKZE07ErkV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}